{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification vs Detection: Visualizing differences on simplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import collections\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.visualization import plot_pdf_triplex, plot_prob_triplex, reliability_plot, ECE_plot\n",
    "from utils.ops import onehot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mesh of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.28 ms, sys: 4.25 ms, total: 13.5 ms\n",
      "Wall time: 13.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "indep_probs = np.array([np.array(tup) for tup in itertools.product(np.linspace(0, 1, num=100), repeat=2)])\n",
    "indep_probs = indep_probs[np.where(np.sum(indep_probs, axis=1)<=1)]\n",
    "probs = np.hstack((indep_probs, 1.-np.sum(indep_probs, axis=1, keepdims=True)))\n",
    "\n",
    "target = onehot_encode(np.argmax(probs, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the relative log-likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RLL = np.log(probs + 1e-7)\n",
    "# Start asumming flat prior\n",
    "priors = np.zeros(3) + 1./3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification problem: \n",
    "Choose $t$ such that for any $i \\neq t$ the resulting log-likelihood-ratio $\\lambda^{t}_{i} = \\lambda_{t} - \\lambda_{i}$ is greater than the threshold: $\\theta^{t}_{i} = -log(\\pi_{t}) + log(\\pi_{i})$, where $\\{\\lambda_i\\}$ are the relative-log-likelihoods and $\\{\\pi_i\\}$ is the prior probability distribution.\n",
    "\n",
    "This corresponds to select the class with the highest posterior probability. Assuming a flat prior this is done by simply selecting the maximum over the classifier output.\n",
    "\n",
    "*Note:*\n",
    "The evaluated hypothesis are mutually exclusive, this is incompatible with the decision rule when 2 hypothesis have the same posterior probability and this is maximum. To handle this we take only the first encountered one.\n",
    "\n",
    "**Naive approach:**\n",
    "Start with the set of all possible classes as identified and check for every $t$ and $i$, whenever the condition $\\lambda^{t}_{i} \\geq \\theta^{t}_{i}$ is not met we remove class $t$ from the set of identified classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified = [set([0, 1, 2]) for _ in range(RLL.shape[0])]\n",
    "\n",
    "for t in range(3):\n",
    "    for i in range(3):\n",
    "        if t==i:\n",
    "            continue\n",
    "        llr = RLL[:, t] - RLL[:, i]\n",
    "        th = -np.log(priors[t]) + np.log(priors[i])\n",
    "        for k in range(len(identified)):\n",
    "            if llr[k] < th:\n",
    "                identified[k].discard(t)\n",
    "                \n",
    "identified_naive = np.array([list(k)[0] for k in identified])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Direct approach:** Having already computed the posterior probabilities we can select the class with the highest. Since the logarithm is a monotonically increasing function the analysis can be perform on the *log* domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_RLL = RLL + np.log(priors)\n",
    "identified = np.argmax(posterior_RLL, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether both methods agree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disagreements: 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of disagreements: {}'.format(np.sum(np.abs(identified - identified_naive))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection problem:\n",
    "The detection problem poses a harder constraint in order to recognize a given target, this is: that the posterior probability of the target is above 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
