{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix-Scaling: A Bayesian approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "import collections\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "\n",
    "from utils.data import get_cifar10, load_logits\n",
    "from utils.ops import onehot_encode\n",
    "from utils.metrics import neg_log_likelihood, expected_calibration_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../cifar-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the test set: 10000\n"
     ]
    }
   ],
   "source": [
    "cifar10, ix2label = get_cifar10(data_path, test=True)\n",
    "print(\"Number of samples in the test set: {:d}\".format(cifar10[\"test_labels\"].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = onehot_encode(cifar10['test_labels'])\n",
    "\n",
    "# val/test split\n",
    "random_split = np.random.permutation(10000)\n",
    "\n",
    "val_target = target[random_split[:5000], :]\n",
    "test_target = target[random_split[5000:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_path = '../pretrained-models'\n",
    "net = 'resnet56_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits = load_logits(os.path.join(resnet_path, net))\n",
    "\n",
    "# val/test split\n",
    "val_logits = logits[random_split[:5000], :]\n",
    "test_logits = logits[random_split[5000:], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_mean = np.random.randn(10, 10)\n",
    "w_log_var = np.random.randn(10, 10)\n",
    "\n",
    "b_mean = np.random.randn(10)\n",
    "b_log_var = np.random.randn(10)\n",
    "\n",
    "params = {\n",
    "    'w_mean': w_mean,\n",
    "    'w_log_var': w_log_var,\n",
    "    'b_mean': b_mean,\n",
    "    'b_log_var': b_log_var\n",
    "}\n",
    "\n",
    "## PRIOR\n",
    "prior_w_mean = np.eye(10)\n",
    "prior_b_mean = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(params):\n",
    "    Z_w = np.random.randn(10, 10)\n",
    "    Z_b = np.random.randn(10)\n",
    "    \n",
    "    w = Z_w*np.exp(0.5 * params['w_log_var']) + params['w_mean']\n",
    "    b = Z_b*np.exp(0.5 * params['b_log_var']) + params['b_mean']\n",
    "\n",
    "    return w, b, Z_w, Z_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, params, K=100):\n",
    "    y = np.zeros(X.shape)\n",
    "    for i in range(K):\n",
    "        w, b, _, _ = sample(params)\n",
    "        y += X @ w + b\n",
    "        \n",
    "    y /= K\n",
    "    return softmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELBO(pred, target, params):\n",
    "    LL = -neg_log_likelihood(pred, target)\n",
    "    mean_w_KL = 0.5 * np.mean(np.exp(params['w_log_var'])**2 + (prior_w_mean - params['w_mean'])**2 - 1 - 2*params['w_log_var'])\n",
    "    mean_b_KL = 0.5 * np.mean(np.exp(params['b_log_var'])**2 + (prior_b_mean - params['b_mean'])**2 - 1 - 2*params['b_log_var'])\n",
    "    \n",
    "    ELBO = LL - (mean_w_KL + mean_b_KL)/2.\n",
    "    \n",
    "    return ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, params, batch_size=10, epochs=1000, lambd=0.5, learning_rate=0.0001):\n",
    "    n_steps = X.shape[0]//batch_size + (X.shape[0]%batch_size > 0)\n",
    "    for e in range(epochs):\n",
    "        for j in range(n_steps):\n",
    "            \n",
    "            log_batch = X[j*batch_size:min((j+1)*batch_size, X.shape[0]), :]\n",
    "            y_batch = y[j*batch_size:min((j+1)*batch_size, X.shape[0]), :]\n",
    "            \n",
    "            # Forward pass\n",
    "            w, b, Z_w, Z_b = sample(params)\n",
    "            logits = log_batch @ w + b\n",
    "            \n",
    "            probs = softmax(logits, axis=1)\n",
    "            \n",
    "            # Likelihood backpropagation\n",
    "            dW = np.mean((probs-y_batch).reshape([-1, 10, 1])\n",
    "                         @ log_batch.reshape([-1, 1, 10]), axis=0).T\n",
    "            dw_var = dW * 2*(-(Z_w + params['w_mean'])/np.exp(params['w_log_var']))\n",
    "            dw_log_var = -0.5 * dw_var\n",
    "            dw_mean = 1./np.exp(0.5*params['w_log_var'])\n",
    "            \n",
    "            db = np.mean((probs-y_batch), axis=0)\n",
    "            db_var = db * 2*(-(Z_b + params['b_mean'])/np.exp(params['b_log_var']))\n",
    "            db_log_var = -0.5 * db_var\n",
    "            db_mean = 1./np.exp(0.5*params['b_log_var'])\n",
    "            \n",
    "            # KL backpropagation\n",
    "            dw_mean_KL = -(prior_w_mean - params['w_mean'])\n",
    "            dw_log_var_KL = 0.5*np.exp(params['w_log_var']) - 1\n",
    "            \n",
    "            db_mean_KL = -(prior_b_mean - params['b_mean'])\n",
    "            db_log_var_KL = 0.5*np.exp(params['b_log_var']) - 1\n",
    "            \"\"\"\n",
    "            print('dw_mean: {}'.format(dw_mean))\n",
    "            print('dw_log_var: {}'.format(dw_log_var))\n",
    "            print('db_mean: {}'.format(db_mean))\n",
    "            print('db_log_var: {}'.format(db_log_var))\n",
    "            \n",
    "            print('dw_mean_KL: {}'.format(dw_mean_KL))\n",
    "            print('dw_log_var_KL: {}'.format(dw_log_var_KL))\n",
    "            print('db_mean_KL: {}'.format(db_mean_KL))\n",
    "            print('db_log_var_KL: {}'.format(db_log_var_KL))\n",
    "            \n",
    "            # Update parameters\n",
    "            params['w_mean'] -= learning_rate*(dw_mean - lambd*dw_mean_KL)\n",
    "            params['w_log_var'] -= learning_rate*(dw_log_var - lambd*dw_log_var_KL)\n",
    "            params['b_mean'] -= learning_rate*(db_mean - lambd*db_mean_KL)\n",
    "            params['b_log_var'] -= learning_rate*(db_log_var - lambd*db_log_var_KL)\n",
    "            \n",
    "            print(params)\n",
    "            \"\"\"\n",
    "        if e%100 == 0:\n",
    "            elbo = ELBO(predict(X, params), y, params)\n",
    "            print(\"End of epoch {:d}, ELBO: {:.3e}\".format(e, elbo))\n",
    "    return params \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 0, ELBO: -1.661e+01\n",
      "End of epoch 100, ELBO: -1.630e+01\n",
      "End of epoch 200, ELBO: -1.624e+01\n",
      "End of epoch 300, ELBO: -1.646e+01\n",
      "End of epoch 400, ELBO: -1.633e+01\n",
      "End of epoch 500, ELBO: -1.648e+01\n",
      "End of epoch 600, ELBO: -1.649e+01\n",
      "End of epoch 700, ELBO: -1.650e+01\n",
      "End of epoch 800, ELBO: -1.635e+01\n",
      "End of epoch 900, ELBO: -1.638e+01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-ae29df933c3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-106-faca512587c2>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(X, y, params, batch_size, epochs, lambd, learning_rate)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# Likelihood backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             dW = np.mean((probs-y_batch).reshape([-1, 10, 1])\n\u001b[1;32m---> 17\u001b[1;33m                          @ log_batch.reshape([-1, 1, 10]), axis=0).T\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mdw_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdW\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ_w\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'w_mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'w_log_var'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mdw_log_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdw_var\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = fit(val_logits, val_target, params, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
