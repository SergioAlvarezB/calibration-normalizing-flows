{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix-Scaling: A Bayesian approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "import collections\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.data import get_cifar10, load_logits\n",
    "from utils.ops import onehot_encode\n",
    "from utils.metrics import neg_log_likelihood, expected_calibration_error, accuracy\n",
    "from calibrators import NiceCalibrator, TempScalingCalibrator, MatrixScalingCalibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../cifar-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the test set: 10000\n"
     ]
    }
   ],
   "source": [
    "cifar10, ix2label = get_cifar10(data_path, test=True)\n",
    "print(\"Number of samples in the test set: {:d}\".format(cifar10[\"test_labels\"].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = onehot_encode(cifar10['test_labels'])\n",
    "\n",
    "# val/test split\n",
    "random_split = np.random.permutation(10000)\n",
    "\n",
    "val_target = target[random_split[:5000], :]\n",
    "test_target = target[random_split[5000:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_path = '../pretrained-models'\n",
    "net = 'resnet56_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits = load_logits(os.path.join(resnet_path, net))\n",
    "\n",
    "# val/test split\n",
    "val_logits = logits[random_split[:5000], :]\n",
    "test_logits = logits[random_split[5000:], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_mean = np.random.randn(10, 10)\n",
    "w_log_var = np.random.randn(10, 10)\n",
    "\n",
    "b_mean = np.random.randn(10)\n",
    "b_log_var = np.random.randn(10)\n",
    "\n",
    "params = {\n",
    "    'w_mean': w_mean,\n",
    "    'w_log_var': w_log_var,\n",
    "    'b_mean': b_mean,\n",
    "    'b_log_var': b_log_var\n",
    "}\n",
    "\n",
    "## PRIOR\n",
    "prior_w_mean = np.zeros([10, 10])\n",
    "prior_b_mean = np.zeros(10)\n",
    "\n",
    "prior_w_log_var = np.log(np.zeros([10, 10]) + 1)\n",
    "prior_b_log_var = np.log(np.zeros(10) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(params):\n",
    "    Z_w = np.random.randn(10, 10)\n",
    "    Z_b = np.random.randn(10)\n",
    "    \n",
    "    w = Z_w*np.exp(0.5 * params['w_log_var']) + params['w_mean']\n",
    "    b = Z_b*np.exp(0.5 * params['b_log_var']) + params['b_mean']\n",
    "\n",
    "    return w, b, Z_w, Z_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, params, K=1000):\n",
    "    y = np.zeros(X.shape)\n",
    "    for i in range(K):\n",
    "        w, b, _, _ = sample(params)\n",
    "        y += X @ w + b\n",
    "        \n",
    "    y /= K\n",
    "    return softmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(params):\n",
    "    mean_w_KL = 0.5 * np.mean(np.exp(params['w_log_var']-prior_w_log_var) + ((prior_w_mean - params['w_mean'])**2)/np.exp(prior_w_log_var) - 1 + (prior_w_log_var - params['w_log_var']))\n",
    "    mean_b_KL = 0.5 * np.mean(np.exp(params['b_log_var']-prior_b_log_var) + ((prior_b_mean - params['b_mean'])**2)/np.exp(prior_b_log_var) - 1 + (prior_b_log_var - params['b_log_var']))\n",
    "    \n",
    "    KL = (mean_w_KL + mean_b_KL)/2.\n",
    "    \n",
    "    return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, params, batch_size=16, epochs=1000, lambd=0.1, learning_rate=0.001):\n",
    "    n_steps = X.shape[0]//batch_size + (X.shape[0]%batch_size > 0)\n",
    "    \n",
    "    history = {\n",
    "        'NLL': [],\n",
    "        'mean_KL': [],\n",
    "        'ELBO': [],\n",
    "        'epoch': []\n",
    "    }\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for j in range(n_steps):\n",
    "            \n",
    "            log_batch = X[j*batch_size:min((j+1)*batch_size, X.shape[0]), :]\n",
    "            y_batch = y[j*batch_size:min((j+1)*batch_size, X.shape[0]), :]\n",
    "            \n",
    "            # Forward pass\n",
    "            w, b, Z_w, Z_b = sample(params)\n",
    "            logits = log_batch @ w + b\n",
    "            \n",
    "            probs = softmax(logits, axis=1)\n",
    "            \n",
    "            # Likelihood backpropagation\n",
    "            dW = np.mean((probs-y_batch).reshape([-1, 10, 1])\n",
    "                         @ log_batch.reshape([-1, 1, 10]), axis=0).T\n",
    "            dw_log_var = dW * (-0.5) * np.exp(0.5 * params['w_log_var']) * Z_w\n",
    "            dw_mean = dW\n",
    "            \n",
    "            db = np.mean((probs-y_batch), axis=0)\n",
    "            db_log_var = db * (-0.5) * np.exp(0.5 * params['b_log_var']) * Z_b\n",
    "            db_mean = db\n",
    "            \n",
    "            # KL backpropagation\n",
    "            dw_mean_KL = -(prior_w_mean - params['w_mean'])  # /np.exp(prior_w_log_var)\n",
    "            dw_log_var_KL = 0.5*(np.exp(params['w_log_var']-prior_w_log_var) - 1)\n",
    "            \n",
    "            db_mean_KL = -(prior_b_mean - params['b_mean'])  # /np.exp(prior_b_log_var)\n",
    "            db_log_var_KL = 0.5*(np.exp(params['b_log_var']-prior_b_log_var) - 1)\n",
    "            \n",
    "            \"\"\"\n",
    "            print('dw_mean: {}'.format(dw_mean))\n",
    "            print('dw_log_var: {}'.format(dw_log_var))\n",
    "            print('db_mean: {}'.format(db_mean))\n",
    "            print('db_log_var: {}'.format(db_log_var))\n",
    "            \n",
    "            print('dw_mean_KL: {}'.format(dw_mean_KL))\n",
    "            print('dw_log_var_KL: {}'.format(dw_log_var_KL))\n",
    "            print('db_mean_KL: {}'.format(db_mean_KL))\n",
    "            print('db_log_var_KL: {}'.format(db_log_var_KL))\n",
    "            \"\"\"\n",
    "            \n",
    "            # Update parameters\n",
    "            params['w_mean'] -= learning_rate*(dw_mean + lambd*dw_mean_KL)\n",
    "            params['w_log_var'] -= learning_rate*(dw_log_var + lambd*dw_log_var_KL)\n",
    "            params['b_mean'] -= learning_rate*(db_mean + lambd*db_mean_KL)\n",
    "            params['b_log_var'] -= learning_rate*(db_log_var + lambd*db_log_var_KL)\n",
    "\n",
    "            \n",
    "        nll = neg_log_likelihood(predict(X, params, K=100), y)\n",
    "        kl = KL(params)\n",
    "        elbo = -nll - lambd*kl\n",
    "            \n",
    "        if np.isnan(nll):\n",
    "            print(params)\n",
    "            break\n",
    "        \n",
    "        history['NLL'].append(nll)\n",
    "        history['mean_KL'].append(kl)\n",
    "        history['ELBO'].append(elbo)\n",
    "        history['epoch'].append(e)\n",
    "        \n",
    "        if e%100 == 0:\n",
    "            print(\"End of epoch {:d},NLL: {:.3e}, mean KL: {:.3e}, ELBO: {:.3e}\".format(e, nll, kl, elbo))\n",
    "    return params, history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 0,NLL: 1.204e+00, mean KL: 3.318e+02, ELBO: -4.522e+00\n",
      "End of epoch 100,NLL: 1.282e+00, mean KL: 1.439e+02, ELBO: -2.721e+00\n",
      "End of epoch 200,NLL: 1.236e+00, mean KL: 1.681e+02, ELBO: -2.916e+00\n",
      "End of epoch 300,NLL: 1.203e+00, mean KL: 1.638e+02, ELBO: -2.841e+00\n",
      "End of epoch 400,NLL: 1.216e+00, mean KL: 1.325e+02, ELBO: -2.541e+00\n",
      "End of epoch 500,NLL: 1.320e+00, mean KL: 1.028e+02, ELBO: -2.348e+00\n",
      "End of epoch 600,NLL: 1.211e+00, mean KL: 1.043e+02, ELBO: -2.254e+00\n",
      "End of epoch 700,NLL: 1.265e+00, mean KL: 1.311e+02, ELBO: -2.577e+00\n",
      "End of epoch 800,NLL: 1.291e+00, mean KL: 1.274e+02, ELBO: -2.564e+00\n",
      "End of epoch 900,NLL: 1.297e+00, mean KL: 1.163e+02, ELBO: -2.461e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-dea3e2703733>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-cc64337c4e6e>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(X, y, params, batch_size, epochs, lambd, learning_rate)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_batch\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-c53fc66976c5>\u001b[0m in \u001b[0;36msample\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mZ_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mZ_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ_w\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'w_log_var'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'w_mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params, h = fit(val_logits, val_target, params, batch_size=16, epochs=5000, lambd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "ax_arr[0].plot(h['epoch'], h['NLL'])\n",
    "ax_arr[0].set_ylabel('NLL')\n",
    "ax_arr[0].set_xlabel('epoch')\n",
    "ax_arr[1].plot(h['epoch'], h['mean_KL'])\n",
    "ax_arr[1].set_ylabel('mean_KL')\n",
    "ax_arr[1].set_xlabel('epoch')\n",
    "ax_arr[2].plot(h['epoch'], h['ELBO'])\n",
    "ax_arr[2].set_ylabel('ELBO')\n",
    "ax_arr[2].set_xlabel('epoch')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure calibration performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temp-Scaling\n",
    "temp_scaling_cal = TempScalingCalibrator(val_logits, val_target)\n",
    "print(\"Calibrated using temperature T={:.3f}\\n\\n\".format(temp_scaling_cal.T))\n",
    "\n",
    "val_probs_temp = temp_scaling_cal.predict(val_logits)\n",
    "test_probs_temp = temp_scaling_cal.predict(test_logits)\n",
    "\n",
    "### MAtrix-Scaling\n",
    "mat_scaling_cal = MatrixScalingCalibrator(val_logits, val_target)\n",
    "\n",
    "val_probs_mat = mat_scaling_cal.predict(val_logits)\n",
    "test_probs_mat = mat_scaling_cal.predict(test_logits)\n",
    "\n",
    "\n",
    "\n",
    "### Uncalibrated model\n",
    "val_probs = softmax(val_logits, axis=1)\n",
    "test_probs = softmax(test_logits, axis=1)\n",
    "\n",
    "val_ece = expected_calibration_error(val_probs, val_target)\n",
    "test_ece = expected_calibration_error(test_probs, test_target)\n",
    "\n",
    "val_nll = neg_log_likelihood(val_probs, val_target)\n",
    "test_nll = neg_log_likelihood(test_probs, test_target)\n",
    "\n",
    "val_acc = accuracy(val_probs, val_target)\n",
    "test_acc = accuracy(test_probs, test_target)\n",
    "\n",
    "## Temp-Scaling\n",
    "# Validation set\n",
    "val_nll_temp = neg_log_likelihood(val_probs_temp, val_target)\n",
    "val_ece_temp = expected_calibration_error(val_probs_temp, val_target, bins=15)\n",
    "\n",
    "# Test set\n",
    "test_nll_temp = neg_log_likelihood(test_probs_temp, test_target)\n",
    "test_ece_temp = expected_calibration_error(test_probs_temp, test_target, bins=15)\n",
    "\n",
    "val_acc_temp = accuracy(val_probs_temp, val_target)\n",
    "test_acc_temp = accuracy(test_probs_temp, test_target)\n",
    "\n",
    "\n",
    "## Matrix-Scaling\n",
    "# Validation set\n",
    "val_nll_mat = neg_log_likelihood(val_probs_mat, val_target)\n",
    "val_ece_mat = expected_calibration_error(val_probs_mat, val_target, bins=15)\n",
    "\n",
    "# Test set\n",
    "test_nll_mat = neg_log_likelihood(test_probs_mat, test_target)\n",
    "test_ece_mat = expected_calibration_error(test_probs_mat, test_target, bins=15)\n",
    "\n",
    "val_acc_mat = accuracy(val_probs_mat, val_target)\n",
    "test_acc_mat = accuracy(test_probs_mat, test_target)\n",
    "\n",
    "\n",
    "## Bayesian Matrix-Scaling calibrated\n",
    "val_probs_bms = predict(val_logits, params)\n",
    "test_probs_bms = predict(test_logits, params)\n",
    "\n",
    "val_ece_bms = expected_calibration_error(val_probs_bms, val_target)\n",
    "test_ece_bms = expected_calibration_error(test_probs_bms, test_target)\n",
    "\n",
    "val_nll_bms = neg_log_likelihood(val_probs_bms, val_target)\n",
    "test_nll_bms = neg_log_likelihood(test_probs_bms, test_target)\n",
    "\n",
    "val_acc_bms = accuracy(val_probs_bms, val_target)\n",
    "test_acc_bms = accuracy(test_probs_bms, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(rects, ax):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\n",
    "    Taken from:\n",
    "    'https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py'\n",
    "    \n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.3f}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(2, 2, figsize=(17, 14))\n",
    "fig.suptitle('Calibration of resnet56_v2 on CIFAR10', fontsize=16)\n",
    "\n",
    "\n",
    "ind = np.arange(4)\n",
    "width = 0.35\n",
    "\n",
    "ticks = ['Uncalibrated', 'Temp-Scaling', 'Matrix-Scaling', 'Bayesian Matrix-Scaling']\n",
    "\n",
    "\n",
    "validation = np.array([val_nll, val_nll_temp, val_nll_mat, val_nll_bms])\n",
    "test = np.array([test_nll, test_nll_temp, test_nll_mat, test_nll_bms])\n",
    "\n",
    "\n",
    "rects1 = ax_arr[0, 0].bar(ind, validation, width, color='b', label='Validation set')\n",
    "rects2 = ax_arr[0, 0].bar(ind+width, test, width, color='r', label='Test set')\n",
    "\n",
    "ax_arr[0, 0].set_ylabel('NLL')\n",
    "ax_arr[0, 0].set_title('NLL comparison')\n",
    "ax_arr[0, 0].set_xticks(ind + width / 2)\n",
    "ax_arr[0, 0].set_xticklabels(ticks)\n",
    "ax_arr[0, 0].set_ylim([0, max(validation.max(), test.max())*1.3])\n",
    "ax_arr[0, 0].legend()\n",
    "\n",
    "autolabel(rects1, ax_arr[0, 0])\n",
    "autolabel(rects2, ax_arr[0, 0])\n",
    "\n",
    "\n",
    "validation = np.array([val_ece, val_ece_temp, val_ece_mat, val_ece_bms])*100\n",
    "test = np.array([test_ece, test_ece_temp, test_ece_mat, test_ece_bms])*100\n",
    "\n",
    "rects1 = ax_arr[0, 1].bar(ind, validation, width, color='b', label='Validation set')\n",
    "rects2 = ax_arr[0, 1].bar(ind+width, test, width, color='r', label='Test set')\n",
    "\n",
    "ax_arr[0, 1].set_ylabel('ECE (%)')\n",
    "ax_arr[0, 1].set_title('Expected Calibration Error comparison')\n",
    "ax_arr[0, 1].set_xticks(ind + width / 2)\n",
    "ax_arr[0, 1].set_xticklabels(ticks)\n",
    "ax_arr[0, 1].set_ylim([0, max(validation.max(), test.max())*1.3])\n",
    "ax_arr[0, 1].legend()\n",
    "\n",
    "autolabel(rects1, ax_arr[0, 1])\n",
    "autolabel(rects2, ax_arr[0, 1])\n",
    "\n",
    "\n",
    "validation = 100. - np.array([val_acc, val_acc_temp, val_acc_mat, val_acc_bms])*100\n",
    "test = 100. - np.array([test_acc, test_acc_temp, test_acc_mat, test_acc_bms])*100\n",
    "\n",
    "rects1 = ax_arr[1, 0].bar(ind, validation, width, color='b', label='Validation set')\n",
    "rects2 = ax_arr[1, 0].bar(ind+width, test, width, color='r', label='Test set')\n",
    "\n",
    "ax_arr[1, 0].set_ylabel('Error (%)')\n",
    "ax_arr[1, 0].set_title('Error Rate comparison')\n",
    "ax_arr[1, 0].set_xticks(ind + width / 2)\n",
    "ax_arr[1, 0].set_xticklabels(ticks)\n",
    "ax_arr[1, 0].set_ylim([0, max(validation.max(), test.max())*1.3])\n",
    "ax_arr[1, 0].legend()\n",
    "\n",
    "autolabel(rects1, ax_arr[1, 0])\n",
    "autolabel(rects2, ax_arr[1, 0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
