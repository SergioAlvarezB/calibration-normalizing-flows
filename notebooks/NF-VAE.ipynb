{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A VAE with Normalizing Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import tempfile\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from flows.flows import Flow, PlanarLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.ioff()\n",
    "\n",
    "PI = torch.Tensor([math.pi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\\train-images-idx3-ubyte.gz to C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\\train-labels-idx1-ubyte.gz to C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:\\Users\\sergi\\AppData\\Local\\Temp\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "dim = 784\n",
    "K = 30  # Steps of flow\n",
    "\n",
    "dev = torch.device('cuda')\n",
    "\n",
    "# Load data\n",
    "mnist_dataset = datasets.MNIST(tempfile.gettempdir(), train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infernn(dim, latent_dim):\n",
    "    encoder = nn.Sequential(\n",
    "        nn.Linear(dim, 500),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(500, 2*latent_dim),\n",
    "    )\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gennn(dim, latent_dim):\n",
    "    decoder = nn.Sequential(\n",
    "        nn.Linear(latent_dim, 500),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(500, dim),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "    \n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reconstruction_error(x, x_p):\n",
    "    return -torch.mean(torch.sum(x*torch.log(x_p) + (1.0-x)*torch.log(1.0-x_p), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_KL_divergence(mu, log_var):\n",
    "    KL = -torch.mean(0.5 * torch.sum(1 + log_var - mu**2 - torch.exp(log_var), dim=1))\n",
    "    \n",
    "    return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flow(latent_dim, K):\n",
    "        \n",
    "    return Flow([PlanarLayer(latent_dim) for _ in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_z = np.random.randn(16, latent_dim)\n",
    "fixed_z = torch.Tensor(fixed_z).to(dev)\n",
    "def sample_digits(model, flow):\n",
    "    imas = model(flow(fixed_z)[0][-1]).detach().cpu().numpy()\n",
    "    imas = imas.reshape([16, 28, 28])\n",
    "    return imas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation_digits(intermediate_results):\n",
    "    \n",
    "    fig, ax_arr = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    \n",
    "    imas = intermediate_results[0]\n",
    "    plots = 16*[0]\n",
    "    \n",
    "    for i in range(16):\n",
    "        plots[i] = ax_arr[i//4, i%4].imshow(imas[i], cmap='gray', vmin=0.0, vmax=1.0)\n",
    "        ax_arr[i//4, i%4].axis('off')\n",
    "    \n",
    "    \n",
    "    def update_scat(i):\n",
    "        imas = intermediate_results[i]\n",
    "        for i in range(16):\n",
    "            plots[i].set_data(imas[i])\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update_scat, frames=len(intermediate_results), interval=30)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_prior(n):\n",
    "    z = torch.randn(n, latent_dim)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_posterior(decoder, flow, n):\n",
    "    z = sample_prior(n)\n",
    "    return decoder(flow(z)[0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=200\n",
    "epochs = 500\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = make_infernn(dim, latent_dim).to(dev)\n",
    "decoder = make_gennn(dim, latent_dim).to(dev)\n",
    "flow = make_flow(latent_dim, K).to(dev)\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()) + list(flow.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "KL = []\n",
    "RE = []\n",
    "\n",
    "intermediate_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, at time: 387.99, loss: 1.292e+02, RE: 1.122e+02, KL: 1.721e+01\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e26bdd2770d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0m_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\calibration\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\calibration\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "t0 = time.time()\n",
    "\n",
    "encoder.to(dev)\n",
    "decoder.to(dev)\n",
    "flow.to(dev)\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    cum_loss = 0\n",
    "    cum_RE = 0\n",
    "    cum_KL = 0\n",
    "    count = 0\n",
    "    \n",
    "    for images, _ in train_loader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        images = images.to(dev, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        infer = encoder(images)\n",
    "        mu, log_var = infer[:, :latent_dim], infer[:, latent_dim:]\n",
    "        \n",
    "        z0 = mu + torch.sqrt(torch.exp(log_var)) * torch.randn_like(mu)\n",
    "        zs, log_det = flow(z0)\n",
    "        zk = zs[-1]\n",
    "        \n",
    "        x_p = decoder(zk)\n",
    "        \n",
    "        _RE = compute_reconstruction_error(images, x_p)\n",
    "        _KL = compute_KL_divergence(mu, log_var)\n",
    "        \n",
    "        _loss = _RE + _KL - torch.mean(log_det)\n",
    "\n",
    "        cum_loss += _loss.item()\n",
    "        cum_RE += _RE.item()\n",
    "        cum_KL += _KL.item()\n",
    "        count += 1\n",
    "\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss.append(cum_loss/count)\n",
    "    KL.append(cum_KL/count)\n",
    "    RE.append(cum_RE/count)\n",
    "    intermediate_results.append(sample_digits(decoder, flow))\n",
    "        \n",
    "    if e%5 == 4:\n",
    "        print('epoch: {}, at time: {:.2f}, loss: {:.3e}, RE: {:.3e}, KL: {:.3e}'.format(\n",
    "              e, time.time()-t0, loss[-1], RE[-1], KL[-1]), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_arr = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "ax_arr[0].plot(loss)\n",
    "ax_arr[0].set_yscale('log')\n",
    "ax_arr[0].set_title('Loss')\n",
    "\n",
    "\n",
    "ax_arr[1].plot(RE)\n",
    "ax_arr[1].set_yscale('log')\n",
    "ax_arr[1].set_title('Reconstruction Error')\n",
    "\n",
    "\n",
    "ax_arr[2].plot(KL)\n",
    "ax_arr[2].set_yscale('log')\n",
    "ax_arr[2].set_title('KL')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = create_animation_digits(intermediate_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imas = sample_posterior(decoder.cpu(), flow.cpu(), 3).detach().cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(13, 4))\n",
    "\n",
    "ax[0].imshow(np.reshape(imas[0], [28, 28]), cmap='gray')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(np.reshape(imas[1], [28, 28]), cmap='gray')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(np.reshape(imas[2], [28, 28]), cmap='gray')\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
