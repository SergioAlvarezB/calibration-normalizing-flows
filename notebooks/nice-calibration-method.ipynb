{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NICE for calibration: Comparison against other methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax\n",
    "\n",
    "from utils.data import get_cifar10, load_logits\n",
    "from utils.ops import onehot_encode\n",
    "from utils.metrics import neg_log_likelihood, expected_calibration_error\n",
    "from calibrators import NiceCalibrator, TempScalingCalibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dir = '../cifar-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10, ix2label = get_cifar10(cifar_dir, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the calibration capabilities of each method we are going to calibrate the model on a subset of the test set, and evaluate it on the other subset. Then compare results for each calibration method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = onehot_encode(cifar10['test_labels'])\n",
    "\n",
    "# val/test split\n",
    "val_target = target[:5000, :]\n",
    "test_target = target[5000:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load precomputed logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'resnet32_v1'\n",
    "models_dir = '../pretrained-models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, logits = load_logits(os.path.join(models_dir, model))\n",
    "\n",
    "# val/test split\n",
    "val_logits = logits[:5000, :]\n",
    "test_logits = logits[5000:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the model\n",
    "\n",
    "### Evaluating the uncalibrated model:\n",
    "Negative Log-Likelihood and Expected Calibration Error on validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative log-likelihood of the uncalibrated model on the validation set: 0.277\n",
      "Expected calibration error of the uncalibrated model on the validation set: 0.00788\n",
      "\n",
      "\n",
      "Negative log-likelihood of the uncalibrated model on the test set: 0.258\n",
      "Expected calibration error of the uncalibrated model on the test set: 0.00711\n"
     ]
    }
   ],
   "source": [
    "val_probs = softmax(val_logits, axis=1)\n",
    "test_probs = softmax(test_logits, axis=1)\n",
    "\n",
    "# Validation set\n",
    "val_nll = neg_log_likelihood(val_probs, val_target)\n",
    "val_ece = expected_calibration_error(val_probs, val_target, bins=15)\n",
    "\n",
    "print('Negative log-likelihood of the uncalibrated model on the validation set: {:.3f}'.format(val_nll))\n",
    "print('Expected calibration error of the uncalibrated model on the validation set: {:.5f}'.format(val_ece))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Test set\n",
    "test_nll = neg_log_likelihood(test_probs, test_target)\n",
    "test_ece = expected_calibration_error(test_probs, test_target, bins=15)\n",
    "\n",
    "print('Negative log-likelihood of the uncalibrated model on the test set: {:.3f}'.format(test_nll))\n",
    "print('Expected calibration error of the uncalibrated model on the test set: {:.5f}'.format(test_ece))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Scaling calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated using temperature T=1.765\n"
     ]
    }
   ],
   "source": [
    "temp_scaling_cal = TempScalingCalibrator(val_logits, val_target)\n",
    "print(\"Calibrated using temperature T={:.3f}\".format(temp_scaling_cal.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative log-likelihood on the validation set after temp-scaling calibration: 0.228\n",
      "Expected calibration error on the validation set after temp-scaling calibration: 0.00130\n",
      "\n",
      "\n",
      "Negative log-likelihood on the test set after temp-scaling calibration: 0.214\n",
      "Expected calibration error on the test set after temp-scaling calibration: 0.00150\n"
     ]
    }
   ],
   "source": [
    "val_probs_temp = temp_scaling_cal.predict(val_logits)\n",
    "test_probs_temp = temp_scaling_cal.predict(test_logits)\n",
    "\n",
    "# Validation set\n",
    "val_nll_temp = neg_log_likelihood(val_probs_temp, val_target)\n",
    "val_ece_temp = expected_calibration_error(val_probs_temp, val_target, bins=15)\n",
    "\n",
    "print('Negative log-likelihood on the validation set after temp-scaling calibration: {:.3f}'.format(val_nll_temp))\n",
    "print('Expected calibration error on the validation set after temp-scaling calibration: {:.5f}'.format(val_ece_temp))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Test set\n",
    "test_nll_temp = neg_log_likelihood(test_probs_temp, test_target)\n",
    "test_ece_temp = expected_calibration_error(test_probs_temp, test_target, bins=15)\n",
    "\n",
    "print('Negative log-likelihood on the test set after temp-scaling calibration: {:.3f}'.format(test_nll_temp))\n",
    "print('Expected calibration error on the test set after temp-scaling calibration: {:.5f}'.format(test_ece_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NICE flow calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sergi\\Anaconda3\\envs\\famarch\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\sergi\\Anaconda3\\envs\\famarch\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\Anaconda3\\envs\\famarch\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "nice_cal = NiceCalibrator(val_logits, val_target, layers=4, hidden_size=[10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative log-likelihood on the validation set after NICE calibration: 0.092\n",
      "Expected calibration error on the validation set after NICE calibration: 0.00306\n",
      "\n",
      "\n",
      "Negative log-likelihood on the test set after NICE calibration: 0.477\n",
      "Expected calibration error on the test set after NICE calibration: 0.01186\n"
     ]
    }
   ],
   "source": [
    "val_probs_nice = nice_cal.predict(val_logits)\n",
    "test_probs_nice = nice_cal.predict(test_logits)\n",
    "\n",
    "# Validation set\n",
    "val_nll_nice = neg_log_likelihood(val_probs_nice, val_target)\n",
    "val_ece_nice = expected_calibration_error(val_probs_nice, val_target, bins=15)\n",
    "\n",
    "print('Negative log-likelihood on the validation set after NICE calibration: {:.3f}'.format(val_nll_nice))\n",
    "print('Expected calibration error on the validation set after NICE calibration: {:.5f}'.format(val_ece_nice))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Test set\n",
    "test_nll_nice = neg_log_likelihood(test_probs_nice, test_target)\n",
    "test_ece_nice = expected_calibration_error(test_probs_nice, test_target, bins=15)\n",
    "\n",
    "print('Negative log-likelihood on the test set after NICE calibration: {:.3f}'.format(test_nll_nice))\n",
    "print('Expected calibration error on the test set after NICE calibration: {:.5f}'.format(test_ece_nice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
